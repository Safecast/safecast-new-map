package main
package main

import (
	"flag"
	"fmt"
	"io"




















































































































































































}	runLoadTest(*baseURL, *concurrency, *duration, *testType)	fmt.Printf("  Type:        %s\n\n", *testType)	fmt.Printf("  Duration:    %d seconds\n", *duration)	fmt.Printf("  Concurrency: %d\n", *concurrency)	fmt.Printf("  URL:         %s\n", *baseURL)	fmt.Printf("Starting load test:\n")	flag.Parse()	testType := flag.String("type", "mixed", "Test type: mixed, streaming, or api")	duration := flag.Int("duration", 30, "Test duration in seconds")	concurrency := flag.Int("concurrency", 50, "Number of concurrent requests")	baseURL := flag.String("url", "http://localhost:8765", "Base URL of the safecast server")func main() {}	result.Print()	result.TotalDuration = time.Since(start)	wg.Wait()	close(stopChan)	time.Sleep(time.Duration(duration) * time.Second)	// Wait for test duration	}		}(i)			}				}					return				if time.Now().After(endTime) {				}					mu.Unlock()					result.ResponseTimes = append(result.ResponseTimes, elapsed)					mu.Lock()					}						atomic.AddInt64(&result.CacheMisses, 1)					} else if cacheHeader == "MISS" {						atomic.AddInt64(&result.CacheHits, 1)					if cacheHeader := resp.Header.Get("X-Cache"); cacheHeader == "HIT" {					// Track cache behavior (look for X-Cache header if present)					}						atomic.AddInt64(&result.CompressedBytes, originalSize)					} else {						}							atomic.AddInt64(&result.CompressedBytes, compressedSize)							fmt.Sscanf(cl, "%d", &compressedSize)							var compressedSize int64						if cl := resp.Header.Get("Content-Length"); cl != "" {						// Estimate compressed size from Content-Length if available					if ce := resp.Header.Get("Content-Encoding"); ce == "gzip" {					// Check compression					atomic.AddInt64(&result.TotalBytes, originalSize)					originalSize := int64(len(body))					body, _ := io.ReadAll(resp.Body)					// Read body to get transfer size					atomic.AddInt64(&result.SuccessfulRequests, 1)					defer resp.Body.Close()				} else {					atomic.AddInt64(&result.FailedRequests, 1)				if err != nil {				atomic.AddInt64(&result.TotalRequests, 1)				elapsed := time.Since(start)				resp, err := client.Do(req)				req.Header.Set("Accept-Encoding", "gzip")				req, _ := http.NewRequest("GET", url, nil)				start := time.Now()				url := baseURL + queries[queryIdx]				}				default:					return				case <-stopChan:				select {			for {			queryIdx := workerID % len(queries)			}				"/api/geoip",				"/stream_markers?zoom=12&minLat=40.55&maxLat=40.65&minLon=-74.05&maxLon=-74.02",				"/stream_markers?zoom=10&minLat=40.5&maxLat=40.6&minLon=-74.1&maxLon=-74.0",				"/stream_markers?zoom=8&minLat=40&maxLat=41&minLon=-74&maxLon=-73",			queries := []string{			defer wg.Done()		go func(workerID int) {		wg.Add(1)	for i := 0; i < concurrency; i++ {	// Spawn goroutines	endTime := start.Add(time.Duration(duration) * time.Second)	start := time.Now()	stopChan := make(chan struct{})	var mu sync.Mutex	var wg sync.WaitGroup	}		ResponseTimes: make([]time.Duration, 0),	result := &LoadTestResult{	}		},			MaxIdleConnsPerHost: concurrency,			MaxIdleConns:        concurrency,		Transport: &http.Transport{		Timeout: 30 * time.Second,	client := &http.Client{func runLoadTest(baseURL string, concurrency, duration int, testType string) {}	}		fmt.Printf("  Hit Rate:           %.1f%%\n", hitRate)		hitRate := float64(r.CacheHits) / float64(r.CacheHits+r.CacheMisses) * 100		fmt.Printf("  Cache Misses:       %d\n", r.CacheMisses)		fmt.Printf("  Cache Hits:         %d\n", r.CacheHits)		fmt.Printf("\nCache Performance:\n")	if r.CacheHits+r.CacheMisses > 0 {	}		fmt.Printf("  Mean:               %v\n", time.Duration(int64(total)/int64(len(r.ResponseTimes))))		}			total += t		for _, t := range r.ResponseTimes {		total := time.Duration(0)		fmt.Printf("  P99:                %v\n", r.ResponseTimes[int(float64(len(r.ResponseTimes))*0.99)])		fmt.Printf("  P95:                %v\n", r.ResponseTimes[int(float64(len(r.ResponseTimes))*0.95)])		fmt.Printf("  Median:             %v\n", r.ResponseTimes[len(r.ResponseTimes)/2])		fmt.Printf("  Max:                %v\n", r.ResponseTimes[len(r.ResponseTimes)-1])		fmt.Printf("  Min:                %v\n", r.ResponseTimes[0])		fmt.Printf("\nResponse Times:\n")		})			return r.ResponseTimes[i] < r.ResponseTimes[j]		sort.Slice(r.ResponseTimes, func(i, j int) bool {	if len(r.ResponseTimes) > 0 {	}		fmt.Printf("  Bandwidth Savings:  %.1f%%\n", savings)		fmt.Printf("  Compression Ratio:  %.1f%% of original\n", ratio)		savings := float64(r.TotalBytes-r.CompressedBytes) / float64(r.TotalBytes) * 100		ratio := float64(r.CompressedBytes) / float64(r.TotalBytes) * 100	if r.TotalBytes > 0 {	fmt.Printf("  Compressed Bytes:   %d (%.2f MB)\n", r.CompressedBytes, float64(r.CompressedBytes)/1024/1024)	fmt.Printf("  Original Bytes:     %d (%.2f MB)\n", r.TotalBytes, float64(r.TotalBytes)/1024/1024)	fmt.Printf("\nData Transfer:\n")	fmt.Printf("Requests/sec:         %.2f\n", float64(r.TotalRequests)/r.TotalDuration.Seconds())	fmt.Printf("Total Duration:       %v\n", r.TotalDuration)	fmt.Printf("Failed:               %d\n", r.FailedRequests)	fmt.Printf("Successful:           %d (%.1f%%)\n", r.SuccessfulRequests, float64(r.SuccessfulRequests)/float64(r.TotalRequests)*100)	fmt.Printf("Total Requests:       %d\n", r.TotalRequests)	fmt.Printf("\n=== Load Test Results ===\n")func (r *LoadTestResult) Print() {}	CacheMisses        int64	CacheHits          int64	ResponseTimes      []time.Duration	TotalDuration      time.Duration	CompressedBytes    int64	TotalBytes         int64	FailedRequests     int64	SuccessfulRequests int64	TotalRequests      int64type LoadTestResult struct {)	"time"	"sync/atomic"	"sync"	"sort"	"net/http"